{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 00: Data Fetching\n",
        "\n",
        "This notebook downloads historical stock price data and news data.\n",
        "\n",
        "## Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup and imports\n",
        "import sys\n",
        "from pathlib import Path\n",
        "import os\n",
        "\n",
        "# Detect if running on Colab\n",
        "try:\n",
        "    import google.colab\n",
        "    ON_COLAB = True\n",
        "    PROJECT_ROOT = Path('/content/ml_research_pipeline')\n",
        "    # If project doesn't exist at /content, use current directory\n",
        "    if not PROJECT_ROOT.exists():\n",
        "        PROJECT_ROOT = Path().absolute().parent.parent\n",
        "    print(\"✓ Running on Google Colab\")\n",
        "except ImportError:\n",
        "    ON_COLAB = False\n",
        "    PROJECT_ROOT = Path().absolute().parent.parent\n",
        "    print(\"✓ Running locally\")\n",
        "\n",
        "# Add src to path\n",
        "sys.path.insert(0, str(PROJECT_ROOT / \"src\"))\n",
        "\n",
        "# Load environment variables\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Try loading keys - priority: Colab secrets > keys.env > environment\n",
        "keys_loaded = False\n",
        "\n",
        "if ON_COLAB:\n",
        "    # Try Colab secrets first\n",
        "    try:\n",
        "        from google.colab import userdata\n",
        "        required_keys = ['FINNHUB_API_KEY', 'NEWS_API_KEY', 'TIINGO_API_KEY']\n",
        "        for key in required_keys:\n",
        "            try:\n",
        "                os.environ[key] = userdata.get(key)\n",
        "                keys_loaded = True\n",
        "            except:\n",
        "                pass\n",
        "        if keys_loaded:\n",
        "            print(\"✓ Loaded keys from Colab secrets\")\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "# Try keys.env file\n",
        "if not keys_loaded:\n",
        "    env_file = PROJECT_ROOT / \"keys.env\"\n",
        "    if env_file.exists():\n",
        "        load_dotenv(env_file)\n",
        "        print(\"✓ Loaded keys from keys.env\")\n",
        "        keys_loaded = True\n",
        "    else:\n",
        "        # Try in current directory\n",
        "        env_file = Path(\"keys.env\")\n",
        "        if env_file.exists():\n",
        "            load_dotenv(env_file)\n",
        "            print(\"✓ Loaded keys from local keys.env\")\n",
        "            keys_loaded = True\n",
        "\n",
        "# Set keys directly if not loaded (from keys.env content)\n",
        "if not keys_loaded and not ON_COLAB:\n",
        "    # Fallback: set from known values (for testing)\n",
        "    os.environ['FINNHUB_API_KEY'] = os.getenv('FINNHUB_API_KEY', 'd28ndhhr01qmp5u9g65gd28ndhhr01qmp5u9g660')\n",
        "    os.environ['NEWS_API_KEY'] = os.getenv('NEWS_API_KEY', '9ff201f1e68b4544ab5d358a261f1742')\n",
        "    os.environ['TIINGO_API_KEY'] = os.getenv('TIINGO_API_KEY', 'b815ff7c64c1a7370b9ae8c0b8907673fdb5eb5f')\n",
        "    print(\"✓ Using default keys (add to Colab secrets for production)\")\n",
        "\n",
        "print(f\"Project root: {PROJECT_ROOT}\")\n",
        "print(f\"FINNHUB_API_KEY: {'✓' if os.getenv('FINNHUB_API_KEY') else '✗'}\")\n",
        "print(f\"NEWS_API_KEY: {'✓' if os.getenv('NEWS_API_KEY') else '✗'}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuration\n",
        "TICKER = \"AAPL\"  # Change this to your target stock\n",
        "START_DATE = \"2020-01-01\"\n",
        "END_DATE = \"2023-12-31\"\n",
        "INDEX_SYMBOL = \"^GSPC\"  # S&P 500 for market context\n",
        "\n",
        "print(f\"Fetching data for {TICKER} from {START_DATE} to {END_DATE}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Fetch Price Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from data import PriceFetcher\n",
        "import pandas as pd\n",
        "\n",
        "# Initialize fetcher\n",
        "price_fetcher = PriceFetcher()\n",
        "\n",
        "# Fetch stock prices\n",
        "print(f\"Fetching prices for {TICKER}...\")\n",
        "stock_prices = price_fetcher.fetch(TICKER, START_DATE, END_DATE)\n",
        "print(f\"✓ Fetched {len(stock_prices)} days of price data\")\n",
        "print(f\"Date range: {stock_prices.index.min()} to {stock_prices.index.max()}\")\n",
        "print(f\"\\nFirst few rows:\")\n",
        "print(stock_prices.head())\n",
        "\n",
        "# Save to processed data\n",
        "from utils.config import PROCESSED_DATA_DIR\n",
        "stock_prices.to_csv(PROCESSED_DATA_DIR / f\"{TICKER}_prices.csv\")\n",
        "print(f\"\\n✓ Saved to {PROCESSED_DATA_DIR / f'{TICKER}_prices.csv'}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Fetch Index Data (Market Context)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fetch index data for market context\n",
        "print(f\"Fetching index data for {INDEX_SYMBOL}...\")\n",
        "index_prices = price_fetcher.fetch_index(INDEX_SYMBOL, START_DATE, END_DATE)\n",
        "print(f\"✓ Fetched {len(index_prices)} days of index data\")\n",
        "\n",
        "# Save\n",
        "index_prices.to_csv(PROCESSED_DATA_DIR / f\"{INDEX_SYMBOL.replace('^', '')}_prices.csv\")\n",
        "print(f\"✓ Saved index data\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Fetch News Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from data import NewsFetcher\n",
        "\n",
        "# Initialize news fetcher\n",
        "news_fetcher = NewsFetcher()\n",
        "\n",
        "# Fetch news (this may take a while due to API rate limits)\n",
        "print(f\"Fetching news for {TICKER}...\")\n",
        "print(\"Note: This may take several minutes due to API rate limits\")\n",
        "\n",
        "news_data = news_fetcher.fetch_all(TICKER, START_DATE, END_DATE)\n",
        "\n",
        "if not news_data.empty:\n",
        "    print(f\"✓ Fetched {len(news_data)} news articles\")\n",
        "    print(f\"Date range: {news_data['date'].min()} to {news_data['date'].max()}\")\n",
        "    print(f\"\\nSample headlines:\")\n",
        "    print(news_data[['date', 'headline']].head(10))\n",
        "    \n",
        "    # Save\n",
        "    news_data.to_csv(PROCESSED_DATA_DIR / f\"{TICKER}_news.csv\", index=False)\n",
        "    print(f\"\\n✓ Saved to {PROCESSED_DATA_DIR / f'{TICKER}_news.csv'}\")\n",
        "else:\n",
        "    print(\"⚠ No news data fetched (API keys may be missing or rate limited)\")\n",
        "    print(\"Pipeline will continue with price-only features\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Summary\n",
        "print(\"=\" * 60)\n",
        "print(\"DATA FETCH SUMMARY\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Ticker: {TICKER}\")\n",
        "print(f\"Date range: {START_DATE} to {END_DATE}\")\n",
        "print(f\"\\nPrice data: {len(stock_prices)} days\")\n",
        "print(f\"Index data: {len(index_prices)} days\")\n",
        "print(f\"News articles: {len(news_data) if not news_data.empty else 0}\")\n",
        "\n",
        "print(f\"\\n✓ All data saved to {PROCESSED_DATA_DIR}\")\n",
        "print(\"\\nNext: Run 01_feature_engineering.ipynb\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
