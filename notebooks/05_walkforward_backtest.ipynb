{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 05: Walk-Forward Backtest\n",
        "\n",
        "Run walk-forward backtesting and evaluate ensemble performance."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup\n",
        "import sys\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "PROJECT_ROOT = Path().absolute().parent.parent\n",
        "sys.path.insert(0, str(PROJECT_ROOT / \"src\"))\n",
        "\n",
        "from models import XGBoostModel, LightGBMModel, SentimentModel, RuleBasedModel\n",
        "from ensemble import MetaEnsemble\n",
        "from backtest import WalkForwardBacktest\n",
        "from utils.config import PROCESSED_DATA_DIR, SPECIALIST_MODELS_DIR, META_MODEL_DIR, RESULTS_DIR\n",
        "\n",
        "TICKER = \"AAPL\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load all models\n",
        "xgb = XGBoostModel()\n",
        "xgb.load(SPECIALIST_MODELS_DIR / f\"{TICKER}_xgb.model\")\n",
        "\n",
        "lgb = LightGBMModel()\n",
        "lgb.load(SPECIALIST_MODELS_DIR / f\"{TICKER}_lgb.txt\")\n",
        "\n",
        "sentiment = SentimentModel()\n",
        "sentiment.load(SPECIALIST_MODELS_DIR / f\"{TICKER}_sentiment.pkl\")\n",
        "\n",
        "rule = RuleBasedModel()\n",
        "rule.load(SPECIALIST_MODELS_DIR / f\"{TICKER}_rule.pkl\")\n",
        "\n",
        "ensemble = MetaEnsemble([xgb, lgb, sentiment, rule])\n",
        "ensemble.load(META_MODEL_DIR / f\"{TICKER}_meta_ensemble.pkl\")\n",
        "\n",
        "print(\"\u2713 Loaded all models\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "features = pd.read_csv(PROCESSED_DATA_DIR / f\"{TICKER}_features.csv\", index_col=0, parse_dates=True)\n",
        "prices = pd.read_csv(PROCESSED_DATA_DIR / f\"{TICKER}_prices.csv\", index_col=0, parse_dates=True)\n",
        "\n",
        "feature_cols = [col for col in features.columns \n",
        "                if col not in ['target_return_1d', 'target_direction', 'open', 'high', 'low', 'close', 'volume']]\n",
        "X = features[feature_cols].fillna(0)\n",
        "y = features['target_return_1d']  # Use return for backtesting\n",
        "\n",
        "print(f\"Backtest data: {len(X)} samples\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run walk-forward backtest\n",
        "backtest = WalkForwardBacktest(ensemble, train_window_days=252, test_window_days=21)\n",
        "results = backtest.run(X, prices, y)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"BACKTEST RESULTS\")\n",
        "print(\"=\"*60)\n",
        "for key, value in results['metrics'].items():\n",
        "    print(f\"{key}: {value:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save results\n",
        "backtest.save_results(RESULTS_DIR / f\"{TICKER}_backtest_results.pkl\")\n",
        "results['predictions'].to_csv(RESULTS_DIR / f\"{TICKER}_predictions.csv\")\n",
        "results['actuals'].to_csv(RESULTS_DIR / f\"{TICKER}_actuals.csv\")\n",
        "\n",
        "print(f\"\u2713 Saved results to {RESULTS_DIR}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize results\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "\n",
        "# Prediction distribution\n",
        "axes[0, 0].hist(results['predictions']['signal'], bins=3, alpha=0.7)\n",
        "axes[0, 0].set_title('Signal Distribution')\n",
        "axes[0, 0].set_xlabel('Signal (-1=sell, 0=abstain, 1=buy)')\n",
        "\n",
        "# Confidence over time\n",
        "axes[0, 1].plot(results['predictions']['confidence'])\n",
        "axes[0, 1].set_title('Confidence Over Time')\n",
        "axes[0, 1].set_ylabel('Confidence')\n",
        "\n",
        "# Accuracy by confidence\n",
        "conf_bins = np.linspace(0, 1, 10)\n",
        "bin_centers = (conf_bins[:-1] + conf_bins[1:]) / 2\n",
        "accuracies = []\n",
        "for i in range(len(conf_bins)-1):\n",
        "    mask = (results['predictions']['confidence'] >= conf_bins[i]) & (results['predictions']['confidence'] < conf_bins[i+1])\n",
        "    if mask.sum() > 0:\n",
        "        pred_dir = np.where(results['predictions'].loc[mask, 'signal'] > 0, 1, -1)\n",
        "        actual_dir = results['actuals'].loc[mask, 'actual_direction']\n",
        "        acc = (pred_dir == actual_dir).mean()\n",
        "        accuracies.append(acc)\n",
        "    else:\n",
        "        accuracies.append(0)\n",
        "\n",
        "axes[1, 0].plot(bin_centers, accuracies, 'o-')\n",
        "axes[1, 0].set_title('Accuracy by Confidence Level')\n",
        "axes[1, 0].set_xlabel('Confidence')\n",
        "axes[1, 0].set_ylabel('Accuracy')\n",
        "\n",
        "# Returns distribution\n",
        "axes[1, 1].hist(results['actuals']['actual_return'], bins=50, alpha=0.7)\n",
        "axes[1, 1].set_title('Actual Returns Distribution')\n",
        "axes[1, 1].set_xlabel('Return')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(RESULTS_DIR / f\"{TICKER}_backtest_plots.png\")\n",
        "print(f\"\u2713 Saved plots to {RESULTS_DIR / f'{TICKER}_backtest_plots.png'}\")\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}